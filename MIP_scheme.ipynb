{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a6503a7",
   "metadata": {},
   "source": [
    "## Scheme_creation_script for MIP (Fresh/Takeover/Renewal) and SPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f6d02d",
   "metadata": {},
   "source": [
    "IF FLEXIPF  is present THEN enter PF_MIN AND PF_MAX\n",
    "\n",
    "IF FIXED PF  THEN only  enter PF_MIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b403ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qqqqq pandas jinja2 numpy google-auth openpyxl gspread "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66d2bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json,numpy as np\n",
    "import jinja2   \n",
    "from jinja2 import Template\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from decimal import Decimal, getcontext, ROUND_HALF_UP\n",
    "from typing import Optional\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82129f0",
   "metadata": {},
   "source": [
    "MIP 24M CALCULATOR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38414f1",
   "metadata": {},
   "source": [
    "New Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80037e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High precision for internal math\n",
    "getcontext().prec = 28\n",
    "\n",
    "def mip_24_months(\n",
    "    cx_ltv: int,\n",
    "    monthly_roi,\n",
    "    secure_ltv: int,\n",
    "    pf_min=None,\n",
    "    pf_max=None,\n",
    "    fc=None,\n",
    "    ts_min: int = None,\n",
    "    ts_max: int = None,\n",
    "):\n",
    "    \"\"\"MIP 24-month calculator using Decimal (exact math)\"\"\"\n",
    "\n",
    "    # ---- Convert inputs to Decimal ----\n",
    "    cx_ltv = Decimal(cx_ltv)\n",
    "    secure_ltv = Decimal(secure_ltv)\n",
    "    monthly_roi = Decimal(str(monthly_roi))\n",
    "\n",
    "    pf_min = Decimal(str(pf_min)) if pf_min is not None else None\n",
    "    pf_max = Decimal(str(pf_max)) if pf_max is not None else None\n",
    "    fc = Decimal(str(fc)) if fc is not None else None\n",
    "\n",
    "    # ---- Constants ----\n",
    "    tenure = Decimal(\"24\")\n",
    "    secure_irr = Decimal(\"14.0\")\n",
    "    secure_pf = Decimal(\"0.00\")\n",
    "    TWOPLACES = Decimal(\"0.01\")\n",
    "\n",
    "    # ---- LTV calculation ----\n",
    "    unsecure_ltv = cx_ltv - secure_ltv\n",
    "\n",
    "    # ---- Interest calculation ----\n",
    "    annual_irr = monthly_roi * Decimal(\"12\")\n",
    "\n",
    "    # ---- Unsecured IRR ----\n",
    "    unsec_irr = (\n",
    "        (cx_ltv * annual_irr) - (secure_ltv * secure_irr)\n",
    "    ) / unsecure_ltv\n",
    "\n",
    "    # ---- Flexi PF calculation ----\n",
    "    min_percent_unsecure = Decimal(\"0.00\")\n",
    "    max_percent_unsecure = Decimal(\"0.00\")\n",
    "\n",
    "    if pf_min is not None:\n",
    "        min_percent_unsecure = (\n",
    "            (pf_min * cx_ltv) - (secure_pf * secure_ltv)\n",
    "        ) / unsecure_ltv\n",
    "\n",
    "    if pf_max is not None:\n",
    "        max_percent_unsecure = (\n",
    "            (pf_max * cx_ltv) - (secure_pf * secure_ltv)\n",
    "        ) / unsecure_ltv\n",
    "\n",
    "    # ---- FC calculation ----\n",
    "    fc_charges = Decimal(\"0.00\")\n",
    "    if fc is not None and unsecure_ltv != 0:\n",
    "        fc_charges = (\n",
    "            (fc * cx_ltv) - (secure_pf * secure_ltv)\n",
    "        ) / unsecure_ltv\n",
    "\n",
    "    # ---- FINAL ROUNDING and output----\n",
    "    return (\n",
    "        annual_irr.quantize(TWOPLACES, rounding=ROUND_HALF_UP),\n",
    "        unsecure_ltv,\n",
    "        unsec_irr.quantize(TWOPLACES, rounding=ROUND_HALF_UP),\n",
    "        min_percent_unsecure.quantize(TWOPLACES, rounding=ROUND_HALF_UP),\n",
    "        max_percent_unsecure.quantize(TWOPLACES, rounding=ROUND_HALF_UP),\n",
    "        fc_charges.quantize(TWOPLACES, rounding=ROUND_HALF_UP),\n",
    "        secure_irr.quantize(TWOPLACES, rounding=ROUND_HALF_UP),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d83144e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the annual_irr is  19.08\n",
      "the unsecure_ltv is  13\n",
      "the unsecure_irr is  46.82\n",
      "the min_percent_unsecure is  4.52\n",
      "the max_percent_unsecure is  0.00\n",
      "the fc_charges is  0.00\n",
      "the secure_irr is  14.00\n"
     ]
    }
   ],
   "source": [
    "x=list(mip_24_months(cx_ltv=84,                  #Trial run of the  MIP calculator\n",
    "              monthly_roi=1.59, \n",
    "            secure_ltv=71,      \n",
    "            pf_min=0.7,\n",
    "            ts_min=30000,\n",
    "            ts_max=299999))\n",
    "print(\"the annual_irr is \",x[0])\n",
    "print(\"the unsecure_ltv is \",x[1])\n",
    "print(\"the unsecure_irr is \",x[2])\n",
    "print(\"the min_percent_unsecure is \",x[3])\n",
    "print(\"the max_percent_unsecure is \",x[4])\n",
    "print(\"the fc_charges is \",x[5])\n",
    "print(\"the secure_irr is \",x[6])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0384d913",
   "metadata": {},
   "source": [
    "Load the template_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b7fe215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_templates(template_path: str):\n",
    "#     df = pd.read_csv(template_path)\n",
    "#     df=df.dropna(how='all',axis=0)\n",
    "#     return df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cfc0627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_templates(\n",
    "    service_account_json: str,\n",
    "    spreadsheet_id: str,\n",
    "    worksheet_name: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads a Google Sheet tab using a service account and\n",
    "    returns list[dict] (same output as your CSV version)\n",
    "    \"\"\"\n",
    "\n",
    "    scopes = [\n",
    "        \"https://www.googleapis.com/auth/spreadsheets.readonly\"\n",
    "    ]\n",
    "\n",
    "    creds = Credentials.from_service_account_file(\n",
    "        service_account_json,\n",
    "        scopes=scopes\n",
    "    )\n",
    "\n",
    "    client = gspread.authorize(creds)\n",
    "\n",
    "    worksheet = client.open_by_key(spreadsheet_id).worksheet(worksheet_name)\n",
    "\n",
    "    records = worksheet.get_all_records()\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    df = df.dropna(how=\"all\", axis=0)\n",
    "\n",
    "    return df.to_dict(orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c22c6b",
   "metadata": {},
   "source": [
    "Load the sample.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f933d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample_input(file_path: str):\n",
    "    \"\"\"\n",
    "    Loads the sample.csv exactly as it is without changing header casing.\n",
    "    \"\"\"\n",
    "    # 1. Read the CSV directly\n",
    "    column_dtypes = {\n",
    "        \"template_type\": str,\n",
    "        'cx_ltv':int,\n",
    "        'monthly_roi': float,        \n",
    "        'city_id': str,\n",
    "        'secure_ltv':int,\n",
    "        'pf_min':float,\n",
    "        'pf_max':float,\n",
    "        'upi_mandate':str,\n",
    "        'fc':float,\n",
    "        'ts_min':int,\n",
    "        'ts_max':int,\n",
    "        'tag': str}\n",
    "    df = pd.read_csv(file_path,dtype=column_dtypes)    \n",
    "    df.columns = [str(c).replace(\"\\ufeff\", \"\").strip() for c in df.columns]\n",
    "    df = df.dropna(how=\"all\", axis=0)\n",
    "    input_rows = df.to_dict(orient=\"records\")\n",
    "    return df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666da82d",
   "metadata": {},
   "source": [
    "Cusstomer ltv integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d4d524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ltv_code(ltv: int) -> str:\n",
    "    mapping = {\n",
    "        70: \"s0\", 71: \"s1\", 72: \"s2\", 73: \"s3\", 74: \"s4\", \n",
    "        75: \"s5\", 76: \"s6\", 77: \"s7\", 78: \"s8\", 79: \"s9\",\n",
    "        80: \"e0\", 81: \"e1\", 82: \"e2\", 83: \"e3\", 84: \"e4\", \n",
    "        85: \"e5\", 86: \"e6\", 87: \"e7\", 88: \"e8\", 89: \"e9\",\n",
    "        90: \"n0\"\n",
    "    }\n",
    "    \n",
    "    if ltv in mapping:\n",
    "        return mapping[ltv]\n",
    "    \n",
    "    raise ValueError(f\"No LTV code defined for ltv={ltv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46b96c0",
   "metadata": {},
   "source": [
    "ticket size in refName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5c601ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slab_label(ts_min: int, ts_max: int) -> str:\n",
    "    if ts_max < 300000:\n",
    "        return \"<3L\"\n",
    "\n",
    "    if 300000 <= ts_min and ts_max <= 599999:\n",
    "        return \"3-6L\"\n",
    "\n",
    "    if 600000 <= ts_min and ts_max <= 1199999:\n",
    "        return \"6-12L\"\n",
    "\n",
    "    if ts_max >= 1200000:\n",
    "        return \">12L\"\n",
    "\n",
    "    raise ValueError(f\"Unknown slab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7355ec2",
   "metadata": {},
   "source": [
    "UPI TAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c85662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upi_enabled(upi_mandate:str):\n",
    "    if upi_mandate == \"True\":\n",
    "        return \"True\"\n",
    "    else:\n",
    "        return \"False\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb1cc19",
   "metadata": {},
   "source": [
    "End tag if any  at refName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce86f521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding any tag at the end of refname\n",
    "def tagged(tag):\n",
    "    if pd.isna(tag) or tag is None:\n",
    "        return \"\"\n",
    "    return str(tag).upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d68446d",
   "metadata": {},
   "source": [
    "Highlighting_logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fc42376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_columns(excel_path:str,\n",
    "                      cols_to_hightlight:list[str],\n",
    "                      color:str= \"FFFF00\"):\n",
    "    wb=load_workbook(excel_path)\n",
    "    ws=wb.active\n",
    "\n",
    "    fill=PatternFill(start_color=color,end_color=color,fill_type=\"solid\")\n",
    "\n",
    "    header_to_col = {\n",
    "        cell.value: idx + 1\n",
    "        for idx, cell in enumerate(ws[1])\n",
    "        if cell.value\n",
    "    }\n",
    "\n",
    "    for col_name in cols_to_hightlight:\n",
    "        if col_name not in header_to_col:\n",
    "            print(f\"âš ï¸ Column not found, skipping: {col_name}\")\n",
    "            continue\n",
    "\n",
    "        col_idx = header_to_col[col_name]\n",
    "        for row in range(1, ws.max_row + 1):\n",
    "            ws.cell(row=1, column=col_idx).fill = fill\n",
    "\n",
    "    wb.save(excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b40638c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIGHLIGHT_COLS = ['refName','schemeFlags','SchemeMin','SchemeMax',   #all the columns to be highlighted and checked\n",
    "                  'CityIds','chargeText','refno','customerLtv',\n",
    "                  'OverallInterestCalculation','bs1-ltv','bs1-calculation','bs2-legalName',\n",
    "                  'bs2-calculation','bs2-charge-2','bs2-charge-3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af8a85d",
   "metadata": {},
   "source": [
    "Scheme validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "586445c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheme_validator(\n",
    "    ts_min: int,\n",
    "    ts_max: int,\n",
    "    cx_ltv: int,\n",
    "    secure_ltv: int,\n",
    "    monthly_roi,\n",
    "    annual_irr,\n",
    "    unsec_irr,\n",
    "    pf_min=None,\n",
    "    pf_max=None,\n",
    "    fc=None,\n",
    "):\n",
    "    errors = []\n",
    "    TWOPLACES = Decimal(\"0.01\")\n",
    "\n",
    "\n",
    "    # ---- Convert to Decimal ----\n",
    "    cx_ltv = Decimal(cx_ltv)\n",
    "    secure_ltv = Decimal(secure_ltv)\n",
    "    monthly_roi = Decimal(str(monthly_roi))\n",
    "    annual_irr = Decimal(str(annual_irr))\n",
    "    unsec_irr = Decimal(str(unsec_irr))\n",
    "\n",
    "    pf_min = Decimal(str(pf_min)) if pf_min is not None else None\n",
    "    pf_max = Decimal(str(pf_max)) if pf_max is not None else None\n",
    "    fc = Decimal(str(fc)) if fc is not None else None\n",
    "\n",
    "    # Constants\n",
    "    secure_irr = Decimal(\"14.0\")\n",
    "    secure_pf = Decimal(\"0.00\")\n",
    "\n",
    "    #ticket size\n",
    "    if ts_min is None or ts_max is None or ts_min >= ts_max:\n",
    "        errors.append(\"Ticket Size range is invalid\")\n",
    "\n",
    "    # LTV checks\n",
    "    \n",
    "    if cx_ltv <= 0:\n",
    "        errors.append(\"CX LTV must be greater than 0\")\n",
    "\n",
    "    if secure_ltv < 0 or secure_ltv > cx_ltv:\n",
    "        errors.append(\"Secure LTV must be between 0 and CX LTV\")\n",
    "\n",
    "    unsecure_ltv = cx_ltv - secure_ltv\n",
    "    if unsecure_ltv <= 0:\n",
    "        errors.append(\"Unsecure LTV must be greater than 0\")\n",
    "\n",
    "    # ------------------------\n",
    "    # Reverse check 1: annual â†” monthly\n",
    "    # ------------------------\n",
    "    derived_monthly = (annual_irr / Decimal(\"12\")).quantize(TWOPLACES)\n",
    "    if derived_monthly != monthly_roi:\n",
    "        errors.append(\n",
    "            f\"Monthly ROI reverse check failed \"\n",
    "            f\"(expected {derived_monthly}, got {monthly_roi})\"\n",
    "        )\n",
    "\n",
    "    # ------------------------\n",
    "    # Reverse check 2: unsecure IRR â†” annual\n",
    "    # ------------------------\n",
    "    derived_annual = (\n",
    "        (unsec_irr * unsecure_ltv) + (secure_ltv * secure_irr)\n",
    "    ) / cx_ltv\n",
    "    derived_annual = derived_annual.quantize(TWOPLACES)\n",
    "    if derived_annual != annual_irr:\n",
    "        errors.append(\n",
    "            f\"Unsecure IRR reverse check failed \"\n",
    "            f\"(expected {derived_annual}, got {annual_irr})\"\n",
    "        )\n",
    "\n",
    "    # ------------------------\n",
    "    # Reverse check 3: PF MIN\n",
    "    # ------------------------\n",
    "    if pf_min is not None:\n",
    "        derived_pf_min = (\n",
    "            (pf_min * cx_ltv) - (secure_pf * secure_ltv)\n",
    "        ) / unsecure_ltv\n",
    "        \n",
    "        reconstructed_pf_min = (\n",
    "            (derived_pf_min * unsecure_ltv) + (secure_pf * secure_ltv)\n",
    "        ) / cx_ltv\n",
    "        reconstructed_pf_min = reconstructed_pf_min.quantize(TWOPLACES)\n",
    "        if reconstructed_pf_min != pf_min:\n",
    "            errors.append(\"PF Min reverse check failed\")\n",
    "\n",
    "    # ------------------------\n",
    "    # Reverse check 4: PF MAX\n",
    "    # ------------------------\n",
    "    if pf_max is not None and pf_max!= Decimal(\"0.00\"):\n",
    "        derived_pf_max = (\n",
    "            (pf_max * cx_ltv) - (secure_pf * secure_ltv)\n",
    "        ) / unsecure_ltv\n",
    "\n",
    "        reconstructed_pf_max = (\n",
    "            (derived_pf_max * unsecure_ltv) + (secure_pf * secure_ltv)\n",
    "        ) / cx_ltv\n",
    "        reconstructed_pf_max = reconstructed_pf_max.quantize(TWOPLACES)\n",
    "        if reconstructed_pf_max != pf_max:\n",
    "            errors.append(\"PF Max reverse check failed\")\n",
    "\n",
    "    # ------------------------\n",
    "    # Reverse check 5: FC\n",
    "    # ------------------------\n",
    "    if fc is not None and fc != Decimal(\"0.00\"):\n",
    "        derived_fc = (\n",
    "            (fc * cx_ltv) - (secure_pf * secure_ltv)\n",
    "        ) / unsecure_ltv\n",
    "\n",
    "        reconstructed_fc = (\n",
    "            (derived_fc * unsecure_ltv) + (secure_pf * secure_ltv)\n",
    "        ) / cx_ltv\n",
    "        reconstructed_fc = reconstructed_fc.quantize(TWOPLACES)\n",
    "        if reconstructed_fc != fc:\n",
    "            errors.append(\"FC reverse check failed\")\n",
    "\n",
    "    #final\n",
    "    if errors:\n",
    "        return {\n",
    "            \"status\": \"INVALID\",\n",
    "            \"errors\": errors\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"status\": \"VALID\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03a610b",
   "metadata": {},
   "source": [
    "Main function to make the schemes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6ea4c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Initializing Scheme Generation\n",
      "âœ… Loading input file: C:\\jinja_schemes\\mipfed 24\\sample.csv\n",
      "âœ… Loading template file fromt the google sheet\n",
      "âœ… Data loaded. Found 4 rows to process.\n",
      "--------------------------------------------------\n",
      "ðŸ”„ Processing Row [4/4] | Type: MIP_Renewal...\n",
      "\n",
      "âœ¨ All rows processed!\n",
      "--------------------------------------------------\n",
      "âœ…Saving results to: C:\\jinja_schemes\\output9.xlsx\n",
      "ðŸŽŠ Success! 4 schemes generated successfully.\n",
      "âœ…Check the Highlighted columns in the output Excel file.\n"
     ]
    }
   ],
   "source": [
    "def generate_schemes(input_path,output_path):\n",
    "    print(\"âœ… Initializing Scheme Generation\")\n",
    "\n",
    "    # 1. Loading Data\n",
    "    print(f\"âœ… Loading input file: {input_path}\")\n",
    "    input_rows = load_sample_input(input_path)\n",
    "\n",
    "    print(f\"âœ… Loading template file fromt the google sheet\")\n",
    "\n",
    "    ##service acccount json need to be changed\n",
    "\n",
    "    SERVICE_ACCOUNT_JSON = r\"C:\\Users\\Ingit.Paul.in\\Downloads\\schemes-486410-773d0189a4ce.json\"\n",
    "    SPREADSHEET_ID = \"18QsZeCu0vEET6p-wnxhAljWG8JpQOUTqwVhmJSesN00\"\n",
    "    WORKSHEET_NAME = \"MIP_TEMPLATE\"  \n",
    "\n",
    "    template_rows = load_templates(SERVICE_ACCOUNT_JSON,SPREADSHEET_ID,WORKSHEET_NAME)\n",
    "    \n",
    "    final_schemes = []\n",
    "    total_rows = len(input_rows)\n",
    "    print(f\"âœ… Data loaded. Found {total_rows} rows to process.\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for i, row in enumerate(input_rows, 1):\n",
    "        # Progress indicator\n",
    "        print(f\"ðŸ”„ Processing Row [{i}/{total_rows}] | Type: {row.get('template_type')}...\", end=\"\\r\")\n",
    "\n",
    "        #Helper to safely get float values\n",
    "         \n",
    "        from decimal import Decimal\n",
    "\n",
    "        def get_decimal_or_none(row, key):\n",
    "            val = row.get(key)\n",
    "            if val is None or str(val).strip().lower() in (\"nan\", \"\"):\n",
    "                return None\n",
    "            return Decimal(str(val))\n",
    "\n",
    "\n",
    "        #Logic Mapping (LTV & Slab)\n",
    "        current_ltv = int(row.get(\"cx_ltv\"))\n",
    "        ltv_code = get_ltv_code(current_ltv)\n",
    "          \n",
    "        secure_ltv = row.get(\"secure_ltv\")\n",
    "        monthly_roi = row.get(\"monthly_roi\")\n",
    "\n",
    "        \n",
    "        ts_min = int(row.get(\"ts_min\"))\n",
    "        ts_max = int(row.get(\"ts_max\"))\n",
    "        slab_label = get_slab_label(ts_min, ts_max) \n",
    "        #UPI TAG\n",
    "        upi_tag = upi_enabled(row.get(\"upi_mandate\"))\n",
    "\n",
    "        #city\n",
    "        city_id = row.get(\"city_id\")\n",
    "\n",
    "        #adding tags at the end\n",
    "        end_tags=tagged(row.get(\"tag\"))\n",
    "    \n",
    "        #Run Calculation (MIP24M)\n",
    "        (annual_irr, unsecure_ltv, unsec_irr, min_percent_unsecure, max_percent_unsecure, \n",
    "        fc_charges, secure_irr)= mip_24_months(\n",
    "            cx_ltv=get_decimal_or_none(row, \"cx_ltv\"),\n",
    "            monthly_roi=get_decimal_or_none(row, \"monthly_roi\"),\n",
    "            secure_ltv=get_decimal_or_none(row, \"secure_ltv\"),\n",
    "            pf_min=get_decimal_or_none(row, \"pf_min\"),\n",
    "            pf_max=get_decimal_or_none(row, \"pf_max\"),\n",
    "            fc=get_decimal_or_none(row, \"fc\")\n",
    "        )\n",
    "\n",
    "        #validation check\n",
    "        validation = scheme_validator(\n",
    "            ts_min=row.get(\"ts_min\"),\n",
    "            ts_max=row.get(\"ts_max\"),\n",
    "            cx_ltv=get_decimal_or_none(row, \"cx_ltv\"),\n",
    "            secure_ltv=get_decimal_or_none(row, \"secure_ltv\"),\n",
    "            monthly_roi=get_decimal_or_none(row, \"monthly_roi\"),\n",
    "            annual_irr=annual_irr,\n",
    "            unsec_irr=unsec_irr,\n",
    "            pf_min=get_decimal_or_none(row, \"pf_min\"),\n",
    "            pf_max=get_decimal_or_none(row, \"pf_max\"),\n",
    "            fc=get_decimal_or_none(row, \"fc\"),\n",
    "        )\n",
    "        if validation[\"status\"] == \"INVALID\":\n",
    "            error_msg = \", \".join(validation[\"errors\"])\n",
    "            print(f\"\\nâŒ Skipping Row {i} | Error: {error_msg}\")\n",
    "            continue\n",
    "\n",
    "        # 4. Build Context (Adding the new labels here)\n",
    "        context = {\n",
    "            **row,\n",
    "            \"end_tags\": end_tags,\n",
    "            \"upi_tag\": upi_tag,\n",
    "            \"ltv_code\": ltv_code,      \n",
    "            \"slab_label\": slab_label,  \n",
    "            \"annual_irr\": annual_irr,\n",
    "            \"city_id\":city_id,    \n",
    "            \"unsec_irr\": unsec_irr,\n",
    "            \"min_percent_unsecure\": min_percent_unsecure,\n",
    "            \"max_percent_unsecure\": max_percent_unsecure,\n",
    "            \"fc_charges\": fc_charges,\n",
    "            \"secure_irr\": secure_irr\n",
    "        }\n",
    "        \n",
    "        #cleaning the NaN values\n",
    "        for k, v in context.items():\n",
    "            if pd.isna(v):\n",
    "                context[k] = \"\"\n",
    "            elif isinstance(v, float):\n",
    "                context[k] = f\"{v:.2f}\"\n",
    "            else:\n",
    "                context[k] = v\n",
    "\n",
    "        # Matching & Rendering templates\n",
    "        t_type = row.get(\"template_type\")\n",
    "        template = next((t for t in template_rows if t.get(\"template_type\") == t_type), None)\n",
    "\n",
    "        if template:\n",
    "            rendered_scheme = {}\n",
    "            for key, value in template.items():\n",
    "                if isinstance(value, str) and \"{{\" in value:\n",
    "                    rendered_scheme[key] = Template(value).render(context)\n",
    "                else:\n",
    "                    rendered_scheme[key] = value\n",
    "            \n",
    "            final_schemes.append(rendered_scheme)\n",
    "        else:\n",
    "            print(f\"\\nâš ï¸ Warning: No template match for type '{t_type}' at row {i}\")\n",
    "\n",
    "    print(f\"\\n\\nâœ¨ All rows processed!\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # 6. Output to New File\n",
    "    if final_schemes:\n",
    "        print(f\"âœ…Saving results to: {output_path}\")\n",
    "        df_output = pd.DataFrame(final_schemes)\n",
    "        \n",
    "        if \"template_type\" in df_output.columns:\n",
    "            df_output = df_output.drop(columns=[\"template_type\"])\n",
    "            \n",
    "        df_output.to_excel(output_path, index=False)\n",
    "        print(f\"ðŸŽŠ Success! {len(final_schemes)} schemes generated successfully.\")\n",
    "        \n",
    "        #Highlighting important columns      \n",
    "\n",
    "        highlight_columns(excel_path=output_path,cols_to_hightlight=HIGHLIGHT_COLS)\n",
    "\n",
    "        print(\"âœ…Check the Highlighted columns in the output Excel file.\")\n",
    "    else:\n",
    "        print(\"âŒError: No schemes were generated. Please check your template_type values.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_schemes(\n",
    "        input_path=r\"C:\\jinja_schemes\\mipfed 24\\sample.csv\",         ## UPLOAD THE CSV FILE FROM HERE\n",
    "        output_path=r\"C:\\jinja_schemes\\output9.xlsx\"              ## THIS IS WHERE YOU WANT TO SAVE THE OUTPUT FILE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26704bf3",
   "metadata": {},
   "source": [
    "# End of the main loop\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "review",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
